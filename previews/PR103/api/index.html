<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · AbstractGPs.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">AbstractGPs.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>API</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/regression_1d/">One-dimensional regression</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/master/docs/src/api.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.AbstractGP" href="#AbstractGPs.AbstractGP"><code>AbstractGPs.AbstractGP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">abstract type AbstractGP end</code></pre><p>Supertype for various Gaussian process (GP) types. A common interface is provided for interacting with each of these objects. See [1] for an overview of GPs.</p><p>[1] - C. E. Rasmussen and C. Williams. &quot;Gaussian processes for machine learning&quot;.  MIT Press. 2006.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL3-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.ConstMean" href="#AbstractGPs.ConstMean"><code>AbstractGPs.ConstMean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ConstMean{T&lt;:Real} &lt;: MeanFunction</code></pre><p>Returns <code>c</code> everywhere.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/gp/mean_function.jl#LL20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.CustomMean" href="#AbstractGPs.CustomMean"><code>AbstractGPs.CustomMean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CustomMean{Tf} &lt;: MeanFunction</code></pre><p>A wrapper around whatever unary function you fancy. Must be able to be mapped over an <code>AbstractVector</code> of inputs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/gp/mean_function.jl#LL32-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.FiniteGP" href="#AbstractGPs.FiniteGP"><code>AbstractGPs.FiniteGP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FiniteGP{Tf&lt;:AbstractGP, Tx&lt;:AbstractVector, TΣy}</code></pre><p>The finite-dimensional projection of the AbstractGP <code>f</code> at <code>x</code>. Assumed to be observed under Gaussian noise with zero mean and covariance matrix <code>Σ</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.GP" href="#AbstractGPs.GP"><code>AbstractGPs.GP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GP{Tm&lt;:MeanFunction, Tk&lt;:Kernel}</code></pre><p>A Gaussian Process (GP) with known <code>mean</code> and <code>kernel</code>. See e.g. [1] for an introduction.</p><p><strong>Zero Mean</strong></p><p>If only one argument is provided, assume the mean to be zero everywhere:</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());
<!-- NAVBAR START -->
<style>
    html {
        scroll-padding-top: calc(55px + 1rem);
    }

    /* Documenter css tweaks */
    .docs-sidebar {
        margin-top: 3.75rem;
    }

    #documenter {
        margin-top: 3.75rem;
    }

    .docs-version-selector {
        margin-bottom: 60px !important;
    }

    @media screen and (max-width: 1056px) {
        .docs-version-selector {
            margin-bottom: 60px !important;
        }

        .docs-sidebar {
            margin-top: 0 !important;
        }
    }
    /* Documenter css tweaks ends here */

    :root {
        --heading-color: white;
        --item-color: rgb(165, 165, 165);
        --primary-bg: #073c44;
        --hover-color: #8faad2;
    }

    .ext-navigation {
        position: fixed;
        height: 3.75rem;
        top: 0;
        width: 100%;
        background-color: var(--primary-bg);
        z-index: 1000;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        display: flex;
        align-items: center;
        padding: 0 1.0625rem;
        transition: transform 0.3s;
    }

    .ext-navbar-logo {
        margin-left: 0.625rem;
    }

    .ext-nav-links {
        display: flex;
        align-items: center;
        list-style-type: none;
        margin: 0;
        padding: 0;
        flex-grow: 1;
    }

    .ext-nav-links li {
        margin-left: 1rem !important;
    }

    .ext-nav-link {
        color: white !important;
        text-decoration: none;
        font-size: 1.0625rem !important;
        transition: color 0.2s ease;
        cursor: pointer;
    }

    .ext-nav-link:hover,
    .ext-navbar-item-single a:hover {
        color: var(--hover-color) !important;
    }

    .ext-navbar-item-single a {
        color: #fff !important;
    }

    .ext-menu-toggle {
        display: none;
        font-size: 1.5rem;
        color: white;
        cursor: pointer;
    }

    .ext-dropdown {
        display: none;
        grid-template-columns: 1fr 1fr 1fr 1fr;
        grid-template-rows: auto auto auto;
        padding: 1.875rem;
        position: absolute;
        width: 100%;
        left: 0;
        background-color: #083c44;
        line-height: 1.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
        transform: translateY(-0.625rem);
    }

    #library-handler::after {
        content: "▼";
        font-size: 0.6875rem;
        margin-left: 0.3125rem;
        transition: transform 0.3s ease-in-out;
    }

    #library-handler.open::after {
        content: "▲";
    }

    .ext-dropdown.show {
        display: grid;
        opacity: 1;
        transform: translateY(0);
    }

    .ext-dropdown ul {
        height: auto;
        width: 12.5rem;
        margin-bottom: 1.25rem;
    }

    .ext-dropdown ul li {
        text-align: left;
    }

    .navbar-sub-item {
        list-style: none;
    }

    .ext-dropdown ul a li {
        color: var(--item-color);
        width: 15.625rem;
        border-radius: 3px;
        padding: 0.125rem 0.625rem;
        transition: background-color 0.2s ease;
    }

    .ext-dropdown ul a li:hover {
        background-color: rgba(107, 107, 107, 0.5);
    }

    .ext-dropdown-item-heading {
        color: var(--heading-color);
        text-align: center;
    }

    /* Responsive styling */
    @media (max-width: 966px) {
        .ext-dropdown {
            grid-template-columns: 1fr 1fr 1fr;
        }
    }

    @media (max-width: 768px) {
        .ext-nav-links {
            display: none;
            flex-direction: column;
            width: 100%;
            background-color: var(--primary-bg);
            position: absolute;
            top: 3.75rem;
            left: 0;
            padding: 0.625rem 0;
            height: auto;
            overflow-y: auto;
            scrollbar-width: thin;
            scrollbar-color: rgb(141, 141, 141) grey;
        }

        .ext-nav-links.show {
            display: flex;
        }

        .ext-nav-links li {
            margin: 0.625rem 0;
            text-align: center;
        }

        .ext-menu-toggle {
            display: block;
            margin-left: auto;
        }

        .ext-navigation.hide {
            transform: translateY(-3.75rem);
        }

        .ext-dropdown {
            place-content: center;
            text-align: center;
            grid-template-columns: 1fr;
            line-height: 1.25rem;
            padding: 0.625rem;
        }

        .ext-dropdown ul {
            width: 100%;
            text-align: center;
            margin-bottom: 0.3125rem;
        }

        .ext-dropdown ul li {
            text-align: center;
        }

        .ext-dropdown ul a li {
            width: 100%;
        }

        .ext-dropdown ul a li:hover {
            background-color: var(--primary-bg);
            color: #fff;
        }

        /* Modified scroll bar */
        .ext-nav-links::-webkit-scrollbar {
            width: 5px;
        }

        .ext-nav-links::-webkit-scrollbar-track {
            box-shadow: inset 0 0 5px grey;
        }

        .ext-nav-links::-webkit-scrollbar-thumb {
            background: rgb(141, 141, 141);
            border-radius: 3px;
        }

        .ext-nav-links::-webkit-scrollbar-thumb:hover {
            background: #9b9b9b;
        }
    }
    @media only screen and (max-width: 768px) {
        .turing-logo {
            display: none !important;
        }
    }
    @media only screen and (min-width: 768px) {
        .turing-collab {
            display: none !important;
        }
    }
</style>
<nav class="ext-navigation">
    <a href="https://github.com/JuliaGaussianProcesses">
        <img src="https://avatars.githubusercontent.com/u/57909728?s=200&v=4" alt="JuliaGP Logo" class="ext-navbar-logo" height="24px" width="40px">
    </a>
    <a style="color: white !important; font-size: 21.25px !important; margin-left: 10px;" href="https://github.com/JuliaGaussianProcesses">JuliaGP</a>
    <ul class="ext-nav-links">
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/">AbstractGPs</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/">KernelFunctions</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/GPLikelihoods.jl/">GPLikelihoods</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/">ApproximateGPs</a>
        </li>
        <li>
            <a class="ext-nav-link turing-collab" href="https://turinglang.org">Co-developed with Turing.jl</a>
        </li>
        <!-- Add a Dropdown with these classes in case it's required so that the current CSS works fine -->
        <!-- <li>
            <p class="ext-nav-link" id="library-handler">Libraries</p>
            <div class="ext-dropdown" id="ext-dropdown-items">
                <ul>
                    <li class="ext-dropdown-item-heading">Modellinglanguages</li>
                    <a href="https://turinglang.org/DynamicPPL.jl/">
                        <li>DynamicPPL</li>
                    </a>
                    <a href="https://turinglang.org/JuliaBUGS.jl/">
                        <li>JuliaBUGS</li>
                    </a>
                    <a href="https://turinglang.org/TuringGLM.jl/">
                        <li>TurineGLM</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">MCMC</li>
                    <a href="https://turinglang.org/AdvancedHMC.jl/">
                        <li>AdvancedHMC</li>
                    </a>
                    <a href="https://turinglang.org/AbstractMCMC.jl/">
                        <li>AbstractMCMC</li>
                    </a>
                    <a href="https://github.com/theogf/ThermodynamicIntegration.jl">
                        <li>ThermodynamicIntegration</li>
                    </a>
                    <a href="https://turinglang.org/AdvancedPS.jl/">
                        <li>AdvancedPS</li>
                    </a>
                    <a href="https://turinglang.org/EllipticalSliceSampling.jl/">
                        <li>EllipticalSliceSampling</li>
                    </a>
                    <a href="https://turinglang.org/NestedSamplers.jl/">
                        <li>NestedSamplers</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Diagnostics</li>
                    <a href="https://turinglang.org/MCMCChains.jl/">
                        <li>MCMCChains</li>
                    </a>
                    <a href="https://turinglang.org/MCMCDiagnosticTools.jl/">
                        <li>MCMCDiagnosticTools</li>
                    </a>
                    <a href="https://turinglang.org/ParetoSmooth.jl/">
                        <li>ParetoSmooth</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Gaussion Processes</li>
                    <a href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/">
                        <li>AbstractGPs</li>
                    </a>
                    <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/">
                        <li>KernelFunctions</li>
                    </a>
                    <a href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/">
                        <li>ApproximateGPs</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/Bijectors.jl/">Bijectors</a>
                    </li>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/TuringCallbacks.jl/">TuringCallbacks</a>
                    </li>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/TuringBenchmarking.jl/">TuringBenchmarking</a>
                    </li>
                </ul>
            </div>
        </li> -->
    </ul>
    <a href="https://turinglang.org/" title="Co-developed with Turing.jl">
        <img src="https://turinglang.org/assets/images/turing-logo.svg" alt="Turing Logo" class="ext-navbar-logo turing-logo" height="24px" width="40px">
    </a>
    <!-- Github Logo -->
    <!-- <a href="https://github.com/JuliaGaussianProcesses/">
        <svg width="32px" height="32px" viewBox="-8.2 -8.2 36.40 36.40" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" fill="#000000">
            <g id="SVGRepo_bgCarrier" stroke-width="0"></g>
            <g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g>
            <g id="SVGRepo_iconCarrier">
                <title>github [#142]</title>
                <desc>Created with Sketch.</desc>
                <defs></defs>
                <g id="Page-1" stroke-width="0.0002" fill="none" fill-rule="evenodd">
                    <g id="Dribbble-Light-Preview" transform="translate(-140.000000, -7559.000000)" fill="#ffffff">
                        <g id="icons" transform="translate(56.000000, 160.000000)">
                            <path
                                d="M94,7399 C99.523,7399 104,7403.59 104,7409.253 C104,7413.782 101.138,7417.624 97.167,7418.981 C96.66,7419.082 96.48,7418.762 96.48,7418.489 C96.48,7418.151 96.492,7417.047 96.492,7415.675 C96.492,7414.719 96.172,7414.095 95.813,7413.777 C98.04,7413.523 100.38,7412.656 100.38,7408.718 C100.38,7407.598 99.992,7406.684 99.35,7405.966 C99.454,7405.707 99.797,7404.664 99.252,7403.252 C99.252,7403.252 98.414,7402.977 96.505,7404.303 C95.706,7404.076 94.85,7403.962 94,7403.958 C93.15,7403.962 92.295,7404.076 91.497,7404.303 C89.586,7402.977 88.746,7403.252 88.746,7403.252 C88.203,7404.664 88.546,7405.707 88.649,7405.966 C88.01,7406.684 87.619,7407.598 87.619,7408.718 C87.619,7412.646 89.954,7413.526 92.175,7413.785 C91.889,7414.041 91.63,7414.493 91.54,7415.156 C90.97,7415.418 89.522,7415.871 88.63,7414.304 C88.63,7414.304 88.101,7413.319 87.097,7413.247 C87.097,7413.247 86.122,7413.234 87.029,7413.87 C87.029,7413.87 87.684,7414.185 88.139,7415.37 C88.139,7415.37 88.726,7417.2 91.508,7416.58 C91.513,7417.437 91.522,7418.245 91.522,7418.489 C91.522,7418.76 91.338,7419.077 90.839,7418.982 C86.865,7417.627 84,7413.783 84,7409.253 C84,7403.59 88.478,7399 94,7399"
                                id="github-[#142]">
                            </path>
                        </g>
                    </g>
                </g>
            </g>
        </svg>
    </a> -->
    <span class="ext-menu-toggle">&#9776;</span>
</nav>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        const menuToggle = document.querySelector(".ext-menu-toggle");
        const navLinks = document.querySelector(".ext-nav-links");
        const nav = document.querySelector(".ext-navigation");
        const navigationHandler = document.getElementById("library-handler");
        const navigationItemsContainer =
            document.getElementById("ext-dropdown-items");
        let lastScrollY = window.scrollY;

        function setAppropriateHeight() {
            if (window.innerWidth <= 768) {
                const viewportHeight = window.innerHeight;
                const navHeight = nav.offsetHeight;
                navLinks.style.maxHeight = `${viewportHeight - navHeight}px`;
                navLinks.style.overflowY = "auto";
            } else {
                navLinks.style.maxHeight = "";
                navLinks.style.overflowY = "";
            }
        }

        // Toggle main menu for mobile
        menuToggle.addEventListener("click", () => {
            navLinks.classList.toggle("show");
            if (navLinks.classList.contains("show")) {
                setAppropriateHeight();
                // Ensure the dropdown is hidden when menu is first opened
                navigationItemsContainer.style.display = "none";
                navigationItemsContainer.classList.remove("show");
            }
        });

        // Close menus if clicked outside
        document.addEventListener("click", (event) => {
            if (
                !navLinks.contains(event.target) &&
                !menuToggle.contains(event.target)
            ) {
                navLinks.classList.remove("show");
                navigationItemsContainer.classList.remove("show");
                navigationHandler.classList.remove("open");
            }
        });

        // Hide navigation bar on scroll down in mobile view
        window.addEventListener("scroll", () => {
            if (window.innerWidth <= 768) {
                nav.classList.toggle("hide", window.scrollY > lastScrollY);
                lastScrollY = window.scrollY;
            }
        });

        // Library API script
        navigationHandler.addEventListener("click", (event) => {
            event.preventDefault(); // Prevent default action of the link
            if (navigationItemsContainer.classList.contains("show")) {
                navigationItemsContainer.classList.remove("show");
                navigationHandler.classList.remove("open");
                setTimeout(() => {
                    navigationItemsContainer.style.display = "none";
                }, 500); // Match the timeout to the CSS transition duration
            } else {
                navigationItemsContainer.style.display = "grid";
                navigationHandler.classList.add("open");
                setTimeout(() => {
                    navigationItemsContainer.classList.add("show");
                }, 10); // Delay to ensure the display change takes effect before adding class
            }
            setAppropriateHeight(); // Recalculate height when dropdown changes
        });

        // Handle window resize
        window.addEventListener("resize", setAppropriateHeight);

        // Initial setup
        setAppropriateHeight();
    });
</script>
<!-- NAVBAR END -->

julia&gt; x = randn(5);

julia&gt; mean(f(x)) == zeros(5)
true

julia&gt; cov(f(x)) == kernelmatrix(Matern32Kernel(), x)
true</code></pre><p><strong>Constant Mean</strong></p><p>If a <code>Real</code> is provided as the first argument, assume the mean function is constant with that value</p><pre><code class="language-julia-repl">julia&gt; f = GP(5.0, Matern32Kernel());

julia&gt; x = randn(5);

julia&gt; mean(f(x)) == 5.0 .* ones(5)
true

julia&gt; cov(f(x)) == kernelmatrix(Matern32Kernel(), x)
true</code></pre><p><strong>Custom Mean</strong></p><p>Provide an arbitrary function to compute the mean:</p><pre><code class="language-julia-repl">julia&gt; f = GP(x -&gt; sin(x) + cos(x / 2), Matern32Kernel());

julia&gt; x = randn(5);

julia&gt; mean(f(x)) == sin.(x) .+ cos.(x ./ 2)
true

julia&gt; cov(f(x)) == kernelmatrix(Matern32Kernel(), x)
true</code></pre><p>[1] - C. E. Rasmussen and C. Williams. &quot;Gaussian processes for machine learning&quot;.  MIT Press. 2006.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/gp/gp.jl#LL1-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.LatentFiniteGP" href="#AbstractGPs.LatentFiniteGP"><code>AbstractGPs.LatentFiniteGP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LatentFiniteGP(fx&lt;:FiniteGP, lik)</code></pre><ul><li><code>fx</code> is a <code>FiniteGP</code>.</li><li><code>lik</code> is the log likelihood function which maps sample from f to corresposing </li></ul><p>conditional likelihood distributions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/latent_gp/latent_gp.jl#LL17-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.LatentGP" href="#AbstractGPs.LatentGP"><code>AbstractGPs.LatentGP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LatentGP(f&lt;:GP, lik, Σy)</code></pre><ul><li><code>f</code> is a <code>AbstractGP</code>.</li><li><code>lik</code> is the log likelihood function which maps sample from f to corresposing </li></ul><p>conditional likelihood distributions.</p><ul><li><code>Σy</code> is the observation noise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/latent_gp/latent_gp.jl#LL1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.ZeroMean" href="#AbstractGPs.ZeroMean"><code>AbstractGPs.ZeroMean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ZeroMean{T&lt;:Real} &lt;: MeanFunction</code></pre><p>Returns <code>zero(T)</code> everywhere.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/gp/mean_function.jl#LL3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.approx_posterior-Tuple{VFE,AbstractGPs.FiniteGP,AbstractArray{var&quot;#s16&quot;,1} where var&quot;#s16&quot;&lt;:Real,AbstractGPs.FiniteGP}" href="#AbstractGPs.approx_posterior-Tuple{VFE,AbstractGPs.FiniteGP,AbstractArray{var&quot;#s16&quot;,1} where var&quot;#s16&quot;&lt;:Real,AbstractGPs.FiniteGP}"><code>AbstractGPs.approx_posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">approx_posterior(::VFE, fx::FiniteGP, y::AbstractVector{&lt;:Real}, u::FiniteGP)</code></pre><p>Compute the optimal approximate posterior [1] over the process <code>f</code>, given observations <code>y</code> of <code>f</code> at <code>x</code>, and inducing points <code>u</code>, where <code>u = f(z)</code> for some inducing inputs <code>z</code>.</p><p>[1] - M. K. Titsias. &quot;Variational learning of inducing variables in sparse Gaussian processes&quot;. In: Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics. 2009.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/posterior_gp/approx_posterior_gp.jl#LL10-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.cov_diag-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}" href="#AbstractGPs.cov_diag-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}"><code>AbstractGPs.cov_diag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov_diag(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute only the diagonal elements of <code>cov(f(x))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.dtc-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s15&quot;,1} where var&quot;#s15&quot;&lt;:Real,AbstractGPs.FiniteGP}" href="#AbstractGPs.dtc-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s15&quot;,1} where var&quot;#s15&quot;&lt;:Real,AbstractGPs.FiniteGP}"><code>AbstractGPs.dtc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dtc(f::FiniteGP, y::AbstractVector{&lt;:Real}, u::FiniteGP)</code></pre><p>The Deterministic Training Conditional (DTC) [1]. <code>y</code> are observations of <code>f</code>, and <code>u</code> are pseudo-points.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(1000);

julia&gt; z = range(-5.0, 5.0; length=256);

julia&gt; y = rand(f(x, 0.1));

julia&gt; isapprox(dtc(f(x, 0.1), y, f(z)), logpdf(f(x, 0.1), y); atol=1e-3, rtol=1e-3)
true</code></pre><p>[1] - M. Seeger, C. K. I. Williams and N. D. Lawrence. &quot;Fast Forward Selection to Speed Up Sparse Gaussian Process Regression&quot;. In: Proceedings of the Ninth International Workshop on Artificial Intelligence and Statistics. 2003</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL260-L283">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.elbo-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real,AbstractGPs.FiniteGP}" href="#AbstractGPs.elbo-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real,AbstractGPs.FiniteGP}"><code>AbstractGPs.elbo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">elbo(f::FiniteGP, y::AbstractVector{&lt;:Real}, u::FiniteGP)</code></pre><p>The Titsias Evidence Lower BOund (ELBO) [1]. <code>y</code> are observations of <code>f</code>, and <code>u</code> are pseudo-points, where <code>u = f(z)</code> for some <code>z</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(1000);

julia&gt; z = range(-5.0, 5.0; length=13);

julia&gt; y = rand(f(x, 0.1));

julia&gt; elbo(f(x, 0.1), y, f(z)) &lt; logpdf(f(x, 0.1), y)
true</code></pre><p>[1] - M. K. Titsias. &quot;Variational learning of inducing variables in sparse Gaussian processes&quot;. In: Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics. 2009.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL231-L254">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.marginals-Tuple{AbstractGPs.FiniteGP}" href="#AbstractGPs.marginals-Tuple{AbstractGPs.FiniteGP}"><code>AbstractGPs.marginals</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">marginals(f::FiniteGP)</code></pre><p>Compute a vector of Normal distributions representing the marginals of <code>f</code> efficiently. In particular, the off-diagonal elements of <code>cov(f(x))</code> are never computed.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; fs = marginals(f(x));

julia&gt; mean.(fs) == mean(f(x))
true

julia&gt; std.(fs) == sqrt.(diag(cov(f(x))))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL136-L156">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.mean_and_cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}" href="#AbstractGPs.mean_and_cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}"><code>AbstractGPs.mean_and_cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_cov(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute both <code>mean(f(x))</code> and <code>cov(f(x))</code>. Sometimes more efficient than separately computation, particularly for posteriors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL42-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.mean_and_cov-Tuple{AbstractGPs.FiniteGP}" href="#AbstractGPs.mean_and_cov-Tuple{AbstractGPs.FiniteGP}"><code>AbstractGPs.mean_and_cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_cov(f::FiniteGP)</code></pre><p>Equivalent to <code>(mean(f), cov(f))</code>, but sometimes more efficient to compute them jointly than separately.</p><pre><code class="language-julia-repl">julia&gt; fx = GP(SqExponentialKernel())(range(-3.0, 3.0; length=10), 0.1);

julia&gt; mean_and_cov(fx) == (mean(fx), cov(fx))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL95-L108">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.mean_and_cov_diag-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}" href="#AbstractGPs.mean_and_cov_diag-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}"><code>AbstractGPs.mean_and_cov_diag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_cov_diag(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute both <code>mean(f(x))</code> and the diagonal elements of <code>cov(f(x))</code>. Sometimes more efficient than separately computation, particularly for posteriors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL50-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real}" href="#AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP,AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">posterior(fx::FiniteGP, y::AbstractVector{&lt;:Real})</code></pre><p>Constructs the posterior distribution over <code>fx.f</code> given observations <code>y</code> at <code>x</code> made under noise <code>fx.Σy</code>. This is another <code>AbstractGP</code> object. See chapter 2 of [1] for a recap on exact inference in GPs. This posterior process has mean function</p><pre><code class="language-julia">m_posterior(x) = m(x) + k(x, fx.x) inv(cov(fx)) (y - mean(fx))</code></pre><p>and kernel</p><pre><code class="language-julia">k_posterior(x, z) = k(x, z) - k(x, fx.x) inv(cov(fx)) k(fx.x, z)</code></pre><p>where <code>m</code> and <code>k</code> are the mean function and kernel of <code>fx.f</code> respectively.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/posterior_gp/posterior_gp.jl#LL6-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP{var&quot;#s13&quot;,Tx,TΣ} where TΣ where Tx&lt;:(AbstractArray{T,1} where T) where var&quot;#s13&quot;&lt;:AbstractGPs.PosteriorGP,AbstractArray{var&quot;#s23&quot;,1} where var&quot;#s23&quot;&lt;:Real}" href="#AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP{var&quot;#s13&quot;,Tx,TΣ} where TΣ where Tx&lt;:(AbstractArray{T,1} where T) where var&quot;#s13&quot;&lt;:AbstractGPs.PosteriorGP,AbstractArray{var&quot;#s23&quot;,1} where var&quot;#s23&quot;&lt;:Real}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">posterior(fx::FiniteGP{&lt;:PosteriorGP}, y::AbstractVector{&lt;:Real})</code></pre><p>Constructs the posterior distribution over <code>fx.f</code> when <code>f</code> is itself a <code>PosteriorGP</code> by updating the cholesky factorisation of the covariance matrix and avoiding recomputing it from original covariance matrix. It does this by using <code>update_chol</code> functionality.</p><p>Other aspects are similar to a regular posterior.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/posterior_gp/posterior_gp.jl#LL29-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.sampleplot!-Tuple" href="#AbstractGPs.sampleplot!-Tuple"><code>AbstractGPs.sampleplot!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sampleplot(GP::FiniteGP, samples)</code></pre><p>Plot samples from the given <code>FiniteGP</code>. Make sure to run <code>using Plots</code> before using this  function. </p><p><strong>Example</strong></p><pre><code class="language-julia">using Plots
f = GP(SqExponentialKernel())
sampleplot(f(rand(10)), 10; markersize=5)</code></pre><p>The given example plots 10 samples from the given <code>FiniteGP</code>. The <code>markersize</code> is modified from default of 0.5 to 5.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/788b2c77c10c2160f4794a4d4b6b81a95a90940c/base/#L0-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.sampleplot!-Tuple{RecipesBase.AbstractPlot,Vararg{Any,N} where N}" href="#AbstractGPs.sampleplot!-Tuple{RecipesBase.AbstractPlot,Vararg{Any,N} where N}"><code>AbstractGPs.sampleplot!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sampleplot(GP::FiniteGP, samples)</code></pre><p>Plot samples from the given <code>FiniteGP</code>. Make sure to run <code>using Plots</code> before using this  function. </p><p><strong>Example</strong></p><pre><code class="language-julia">using Plots
f = GP(SqExponentialKernel())
sampleplot(f(rand(10)), 10; markersize=5)</code></pre><p>The given example plots 10 samples from the given <code>FiniteGP</code>. The <code>markersize</code> is modified from default of 0.5 to 5.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/788b2c77c10c2160f4794a4d4b6b81a95a90940c/base/#L0-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.sampleplot-Tuple" href="#AbstractGPs.sampleplot-Tuple"><code>AbstractGPs.sampleplot</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sampleplot(GP::FiniteGP, samples)</code></pre><p>Plot samples from the given <code>FiniteGP</code>. Make sure to run <code>using Plots</code> before using this  function. </p><p><strong>Example</strong></p><pre><code class="language-julia">using Plots
f = GP(SqExponentialKernel())
sampleplot(f(rand(10)), 10; markersize=5)</code></pre><p>The given example plots 10 samples from the given <code>FiniteGP</code>. The <code>markersize</code> is modified from default of 0.5 to 5.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaLang/julia/blob/788b2c77c10c2160f4794a4d4b6b81a95a90940c/base/#L0-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.update_approx_posterior-Tuple{AbstractGPs.ApproxPosteriorGP,AbstractGPs.FiniteGP,AbstractArray{var&quot;#s15&quot;,1} where var&quot;#s15&quot;&lt;:Real}" href="#AbstractGPs.update_approx_posterior-Tuple{AbstractGPs.ApproxPosteriorGP,AbstractGPs.FiniteGP,AbstractArray{var&quot;#s15&quot;,1} where var&quot;#s15&quot;&lt;:Real}"><code>AbstractGPs.update_approx_posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">function update_approx_posterior(
    f_post_approx::ApproxPosteriorGP,
    fx::FiniteGP,
    y::AbstractVector{&lt;:Real}
)</code></pre><p>Update the <code>ApproxPosteriorGP</code> given a new set of observations. Here, we retain the same  of pseudo-points.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/posterior_gp/approx_posterior_gp.jl#LL47-L56">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.update_approx_posterior-Tuple{AbstractGPs.ApproxPosteriorGP,AbstractGPs.FiniteGP}" href="#AbstractGPs.update_approx_posterior-Tuple{AbstractGPs.ApproxPosteriorGP,AbstractGPs.FiniteGP}"><code>AbstractGPs.update_approx_posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">function update_approx_posterior(
    f_post_approx::ApproxPosteriorGP,
    u::FiniteGP,
)</code></pre><p>Update the <code>ApproxPosteriorGP</code> given a new set of pseudo-points to append to the existing  set of pseudo points. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/posterior_gp/approx_posterior_gp.jl#LL99-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.update_chol-Tuple{LinearAlgebra.Cholesky,AbstractArray{T,2} where T,AbstractArray{T,2} where T}" href="#AbstractGPs.update_chol-Tuple{LinearAlgebra.Cholesky,AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>AbstractGPs.update_chol</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia"> update_chol(chol::Cholesky, C12::AbstractMatrix, C22::AbstractMatrix)</code></pre><p>Let <code>C</code> be the positive definite matrix comprising blocks</p><pre><code class="language-julia">C = [C11 C12;
     C21 C22]</code></pre><p>with upper-triangular cholesky factorisation comprising blocks</p><pre><code class="language-julia">U = [U11 U12;
     0   U22]</code></pre><p>where <code>U11</code> and <code>U22</code> are themselves upper-triangular, and <code>U11 = cholesky(C11).U</code>. update_chol computes the updated Cholesky given original <code>chol</code>, <code>C12</code>, and <code>C22</code>.</p><p><strong>Arguments</strong></p><pre><code class="language-none"> - chol::Cholesky: The original cholesky decomposition
 - C12::AbstractMatrix: matrix of size (size(chol.U, 1), size(C22, 1))
 - C22::AbstractMatrix: positive-definite matrix</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/util/common_covmat_ops.jl#LL2-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.rand-Tuple{Random.AbstractRNG,AbstractGPs.FiniteGP,Int64}" href="#Base.rand-Tuple{Random.AbstractRNG,AbstractGPs.FiniteGP,Int64}"><code>Base.rand</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rand(rng::AbstractRNG, f::FiniteGP, N::Int=1)</code></pre><p>Obtain <code>N</code> independent samples from the marginals <code>f</code> using <code>rng</code>. Single-sample methods produce a <code>length(f)</code> vector. Multi-sample methods produce a <code>length(f)</code> x <code>N</code> <code>Matrix</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; rand(f(x)) isa Vector{Float64}
true

julia&gt; rand(MersenneTwister(123456), f(x)) isa Vector{Float64}
true

julia&gt; rand(f(x), 3) isa Matrix{Float64}
true

julia&gt; rand(MersenneTwister(123456), f(x), 3) isa Matrix{Float64}
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL159-L183">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.logpdf-Tuple{AbstractGPs.FiniteGP,Union{AbstractArray{var&quot;#s16&quot;,1}, AbstractArray{var&quot;#s16&quot;,2}} where var&quot;#s16&quot;&lt;:Real}" href="#Distributions.logpdf-Tuple{AbstractGPs.FiniteGP,Union{AbstractArray{var&quot;#s16&quot;,1}, AbstractArray{var&quot;#s16&quot;,2}} where var&quot;#s16&quot;&lt;:Real}"><code>Distributions.logpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">logpdf(f::FiniteGP, y::AbstractVecOrMat{&lt;:Real})</code></pre><p>The logpdf of <code>y</code> under <code>f</code> if is <code>y isa AbstractVector</code>. logpdf of each column of <code>y</code> if <code>y isa Matrix</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; y = rand(f(x));

julia&gt; logpdf(f(x), y) isa Real
true

julia&gt; Y = rand(f(x), 3);

julia&gt; logpdf(f(x), Y) isa AbstractVector{&lt;:Real}
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL193-L215">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.logpdf-Tuple{AbstractGPs.LatentFiniteGP,NamedTuple{(:f, :y),T} where T&lt;:Tuple}" href="#Distributions.logpdf-Tuple{AbstractGPs.LatentFiniteGP,NamedTuple{(:f, :y),T} where T&lt;:Tuple}"><code>Distributions.logpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">logpdf(lfgp::LatentFiniteGP, y::NamedTuple{(:f, :y)})</code></pre><p class="math-container">\[    log p(y, f; x)\]</p><p>Returns the joint log density of the gaussian process output <code>f</code> and real output <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/latent_gp/latent_gp.jl#LL38-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T,AbstractArray{T,1} where T}" href="#Statistics.cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T,AbstractArray{T,1} where T}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::AbstractGP, x::AbstractVector, y::AbstractVector)</code></pre><p>Compute the <code>length(x)</code> by <code>length(y)</code> cross-covariance matrix between <code>f(x)</code> and <code>f(y)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}" href="#Statistics.cov-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute the <code>length(x)</code> by <code>length(x)</code> covariance matrix of the multivariate Normal <code>f(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL21-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.FiniteGP,AbstractGPs.FiniteGP}" href="#Statistics.cov-Tuple{AbstractGPs.FiniteGP,AbstractGPs.FiniteGP}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(fx::FiniteGP, gx::FiniteGP)</code></pre><p>Compute the cross-covariance matrix between <code>fx</code> and <code>gx</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x1 = randn(11);

julia&gt; x2 = randn(13);

julia&gt; cov(f(x1), f(x2)) == kernelmatrix(Matern32Kernel(), x1, x2)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL114-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.FiniteGP}" href="#Statistics.cov-Tuple{AbstractGPs.FiniteGP}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::FiniteGP)</code></pre><p>Compute the covariance matrix of <code>fx</code>.</p><p><strong>Noise-free observations</strong></p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(11);

julia&gt; cov(f(x)) == kernelmatrix(Matern52Kernel(), x)
true</code></pre><p><strong>Isotropic observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; cov(f(x, 0.1)) == kernelmatrix(Matern52Kernel(), x) + 0.1 * I
true</code></pre><p><strong>Independent anisotropic observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; s = rand(11);

julia&gt; cov(f(x, s)) == kernelmatrix(Matern52Kernel(), x) + Diagonal(s)
true</code></pre><p><strong>Correlated observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; A = randn(11, 11); S = A&#39;A;

julia&gt; cov(f(x, S)) == kernelmatrix(Matern52Kernel(), x) + S
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL51-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}" href="#Statistics.mean-Tuple{AbstractGPs.AbstractGP,AbstractArray{T,1} where T}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean(f::AbstractGP, x::AbstractVector)</code></pre><p>Computes the mean vector of the multivariate Normal <code>f(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/abstract_gp.jl#LL14-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{AbstractGPs.FiniteGP}" href="#Statistics.mean-Tuple{AbstractGPs.FiniteGP}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean(fx::FiniteGP)</code></pre><p>Compute the mean vector of <code>fx</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(11);

julia&gt; mean(f(x)) == zeros(11)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/036aeaa4024b23b20dbf4cf2f7839fa98e1677e1/src/abstract_gp/finite_gp.jl#LL34-L48">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../examples/regression_1d/">One-dimensional regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 1 February 2021 00:52">Monday 1 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

